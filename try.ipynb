{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from datetime import datetime\n",
    "\n",
    "# Tải mô hình ngôn ngữ spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "paper_path = \"D:/STUDY/CODE/Paper_retrieval/paper\"\n",
    "OUTPUT_CSV = \"extracted_images_report.csv\"\n",
    "KEYWORDS = [\n",
    "        \"Cu||Li\", \"Li||Cu\", \"Li-Cu\", \"Cu-Li\", \n",
    "        \"coulombic efficiency\", \"CE\", \"coulombic efficiencies\",\n",
    "        \"conductivity\", \"conductivities\", \n",
    "        \"viscosity\", \"viscosities\",\n",
    "        \"lithium metal\", \"electrolyte\", \"anode\", \"cathode\",\n",
    "        \"cycling performance\", \"capacity retention\"\n",
    "    ]\n",
    "SIMILARITY_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image image_p0_xref8.png - Caption: [No caption found]\n",
      "Image image_p0_xref28.png - Caption: Figure 1:  Correlation of two models with the same MSE loss.\n",
      "Image image_p1_xref74.png - Caption: Figure 2:  Proposed No-Reference Speech Quality Assessment model.\n"
     ]
    }
   ],
   "source": [
    "def process_pdf_folder(folder_path, output_csv, keywords=None, similarity_threshold=0.4):\n",
    "    \"\"\"Xử lý tất cả file PDF trong thư mục và lưu kết quả vào CSV\"\"\"\n",
    "    if keywords is None:\n",
    "        keywords = [\n",
    "            \"Cu||Li\", \"Li||Cu\", \"Li-Cu\", \"Cu-Li\", \n",
    "            \"coulombic efficiency\", \"CE\", \"coulombic efficiencies\",\n",
    "            \"conductivity\", \"conductivities\", \n",
    "            \"viscosity\", \"viscosities\"\n",
    "        ]\n",
    "    \n",
    "    # Chuẩn bị embedding cho các từ khóa\n",
    "    keyword_embeddings = {}\n",
    "    for kw in keywords:\n",
    "        doc = nlp(kw)\n",
    "        if doc.vector_norm:\n",
    "            keyword_embeddings[kw] = doc.vector / doc.vector_norm\n",
    "    \n",
    "    # Tạo thư mục lưu ảnh\n",
    "    output_dir = os.path.join(folder_path, \"extracted_images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = [\n",
    "            'pdf_file', 'image_file', 'image_path', 'page', \n",
    "            'caption', 'keywords', 'similarity_scores'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith('.pdf'):\n",
    "                pdf_path = os.path.join(folder_path, filename)\n",
    "                print(f\"\\nProcessing PDF: {filename}\")\n",
    "                \n",
    "                try:\n",
    "                    # Xử lý từng PDF\n",
    "                    pdf_results = process_single_pdf(\n",
    "                        pdf_path, \n",
    "                        keyword_embeddings, \n",
    "                        similarity_threshold,\n",
    "                        output_dir\n",
    "                    )\n",
    "                    \n",
    "                    # Ghi kết quả vào CSV\n",
    "                    for img_data in pdf_results:\n",
    "                        writer.writerow({\n",
    "                            'pdf_file': filename,\n",
    "                            'image_file': img_data['image_filename'],\n",
    "                            'image_path': img_data['image_path'],\n",
    "                            'page': img_data['page'],\n",
    "                            'caption': img_data['caption'],\n",
    "                            'keywords': \"; \".join([k for k, _ in img_data['keywords']]),\n",
    "                            'similarity_scores': \"; \".join([f\"{s:.3f}\" for _, s in img_data['keywords']])\n",
    "                        })\n",
    "                    \n",
    "                    print(f\"  - Extracted {len(pdf_results)} relevant images\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"  - Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nProcessing completed! Results saved to {output_csv}\")\n",
    "\n",
    "def process_single_pdf(pdf_path, keyword_embeddings, similarity_threshold, output_dir):\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    results = []\n",
    "    \n",
    "    for page_num in range(len(pdf)):\n",
    "        page = pdf.load_page(page_num)\n",
    "        \n",
    "        images = page.get_images(full=True)\n",
    "        if not images:\n",
    "            continue\n",
    "        \n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        for img_info in images:\n",
    "            xref = img_info[0]\n",
    "            try:\n",
    "                base_image = pdf.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "            except Exception as e:\n",
    "                print(f\"    - Could not extract image on page {page_num+1}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Tạo tên file ảnh duy nhất\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "            image_filename = f\"img_p{page_num+1}_{xref}_{timestamp}.{image_ext}\"\n",
    "            image_path = os.path.join(output_dir, image_filename)\n",
    "            \n",
    "            with open(image_path, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "            \n",
    "            # Tìm caption\n",
    "            caption = find_image_caption(page, img_info, text_blocks)\n",
    "            \n",
    "            if caption:\n",
    "                # Tính toán similarity với các từ khóa\n",
    "                caption_doc = nlp(caption)\n",
    "                if caption_doc.vector_norm:\n",
    "                    caption_vec = caption_doc.vector / caption_doc.vector_norm\n",
    "                    found_keywords = []\n",
    "                    \n",
    "                    for kw, kw_vec in keyword_embeddings.items():\n",
    "                        similarity = np.dot(caption_vec, kw_vec)\n",
    "                        if similarity >= similarity_threshold:\n",
    "                            found_keywords.append((kw, similarity))\n",
    "                    \n",
    "                    # Sắp xếp theo độ tương đồng giảm dần\n",
    "                    found_keywords.sort(key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "                    if found_keywords:\n",
    "                        results.append({\n",
    "                            'image_filename': image_filename,\n",
    "                            'image_path': image_path,\n",
    "                            'page': page_num + 1,\n",
    "                            'caption': caption,\n",
    "                            'keywords': found_keywords\n",
    "                        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def find_image_caption(page, img_info, text_blocks):\n",
    "    \"\"\"Tìm caption cho hình ảnh dựa trên vị trí\"\"\"\n",
    "    img_rect = page.get_image_bbox(img_info)\n",
    "    best_caption = \"\"\n",
    "    best_distance = float('inf')\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if \"lines\" not in block:\n",
    "            continue\n",
    "            \n",
    "        block_rect = fitz.Rect(block[\"bbox\"])\n",
    "        block_text = \" \".join(\n",
    "            [span[\"text\"] for line in block[\"lines\"] for span in line[\"spans\"]]\n",
    "        ).strip()\n",
    "        \n",
    "        # Kiểm tra xem có phải là caption\n",
    "        if not is_caption_text(block_text):\n",
    "            continue\n",
    "        \n",
    "        # Tính khoảng cách từ hình đến caption\n",
    "        vertical_distance = abs(block_rect.y0 - img_rect.y1)\n",
    "        horizontal_overlap = min(img_rect.x1, block_rect.x1) - max(img_rect.x0, block_rect.x0)\n",
    "        \n",
    "        # Ưu tiên caption gần nhất có overlap ngang\n",
    "        if horizontal_overlap > 0 and vertical_distance < 100:\n",
    "            if vertical_distance < best_distance:\n",
    "                best_caption = block_text\n",
    "                best_distance = vertical_distance\n",
    "    \n",
    "    return best_caption\n",
    "\n",
    "def is_caption_text(text):\n",
    "    \"\"\"Kiểm tra xem text có đặc điểm của caption không\"\"\"\n",
    "    # Kiểm tra các từ chỉ định caption\n",
    "    if re.search(r\"\\b(Fig\\.?|Figure|Table|Scheme|Chart)\\b\", text, re.IGNORECASE):\n",
    "        return True\n",
    "    \n",
    "    # Kiểm tra độ dài phù hợp cho caption\n",
    "    words = text.split()\n",
    "    if 5 < len(words) < 150:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Xử lý tất cả PDF trong thư mục\n",
    "    process_pdf_folder(\n",
    "        folder_path=paper_path,\n",
    "        output_csv=OUTPUT_CSV,\n",
    "        keywords=KEYWORDS,\n",
    "        similarity_threshold=SIMILARITY_THRESHOLD\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
